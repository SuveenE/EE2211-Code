{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e32acce-95ce-447a-b787-9012b25ffd83",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1605688b-f662-4657-9be2-c130921ef8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.7661 5.5284]]\n",
      "[[-0.0718  0.6665]\n",
      " [ 0.0325  0.7073]]\n",
      "[ 4.2897 -2.8824]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assuming X is correctly structured as samples with two features each\n",
    "X = np.array([[45, 9], [50, 10], [63, 12], [70, 8], [80, 4]])\n",
    "#X = np.array([-10, -8, -3, -1, 2, 8]).reshape(-1, 1)\n",
    "#Y = np.array([5, 5, 4, 3, 2, 2]).reshape(-1, 1)\n",
    "# Assuming Y should have samples as rows and targets as columns\n",
    "# Adjusted Y to match common usage patterns for LinearRegression with multiple targets\n",
    "Y = np.array([[6, 5], [9, 6], [8, 9], [3, 2], [2, 4]])\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "\n",
    "# Predict using a sample with the correct shape\n",
    "y_pred = model.predict([[63,9]])  # Note the double brackets to create a 2D array\n",
    "print(y_pred)\n",
    "\n",
    "print(model.coef_)\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc09923-5611-409b-b238-4c4211a3ee4b",
   "metadata": {},
   "source": [
    "### Mean Squared Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57a000e0-e9db-43dd-a75e-1852b41a9ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for output 1: 1.4030198896178283\n",
      "Mean Squared Error for output 2: 2.6545038008955535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "Y_pred = model.predict(X)\n",
    "\n",
    "# Calculate the MSE for each output\n",
    "mse_output_1 = mean_squared_error(Y[:, 0], Y_pred[:, 0])\n",
    "mse_output_2 = mean_squared_error(Y[:, 1], Y_pred[:, 1])\n",
    "\n",
    "print(\"Mean Squared Error for output 1:\", mse_output_1)\n",
    "print(\"Mean Squared Error for output 2:\", mse_output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f96c8f0f-63c0-4a87-affa-86612984ee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Even-determined system (m = d) Demo 3\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import matrix_rank\n",
    "\n",
    "X = np.array([[1, 1], [1, -2]])\n",
    "y = np.array([4, 1])\n",
    "w = inv(X) @ y\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee74bb08-2a2f-4b3f-ae3f-edc43b8206fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.125   0.25  ]\n",
      " [-0.375   0.5   ]\n",
      " [ 0.0137  0.0645]]\n"
     ]
    }
   ],
   "source": [
    "#Over-determined system (m > d) Demo 4\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "X = np.array([[4, -3, 6], [1, 0, 10]])\n",
    "y = np.array([1, 0, 2])\n",
    "w = inv(X.T @ X) @ X.T \n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c77594-c561-47ca-b1c8-9907e5fc5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under-determined system 2 (m < d) Example 3\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import matrix_rank\n",
    "from numpy.linalg import det\n",
    "\n",
    "X = np.array([[1, 2, 3], [1, -2, 3]])\n",
    "y = np.array([2, 1])\n",
    "w = X.T @ inv(X@ X.T) @ y\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bdab09-6f05-4d2d-95ae-2826c036a367",
   "metadata": {},
   "source": [
    "### Linear Classification (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ff060b1-0662-45f1-94ed-e11edce2eed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated w\n",
      "[[ 0.7447]\n",
      " [-0.1277]]\n",
      "Training out\n",
      "[[ 0.234 ]\n",
      " [-0.1489]\n",
      " [-0.5319]\n",
      " [ 0.4894]\n",
      " [ 0.3617]\n",
      " [-0.4043]]\n",
      "Predicted y\n",
      "[[-0.0213]]\n",
      "Predicted y class\n",
      "[[-1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "#Have to include the bias term\n",
    "X = np.array([[1,4], [1,7], [1,10], [1,2], [1,3], [1, 9]])\n",
    "y = np.array([[-1], [-1], [-1], [1], [1], [1]])\n",
    "w = inv(X.T @ X) @ X.T @ y\n",
    "print(\"Estimated w\")\n",
    "print(w)\n",
    "training_out = X@w\n",
    "print(\"Training out\")\n",
    "print(training_out)\n",
    "Xt = np.array([[1,6]])\n",
    "y_predict = Xt @ w\n",
    "print(\"Predicted y\")\n",
    "print(y_predict)\n",
    "y_class_predict = np.sign(y_predict)\n",
    "print(\"Predicted y class\")\n",
    "print(y_class_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151a2b6-df5b-4034-9a83-d32e624caba9",
   "metadata": {},
   "source": [
    "### Linear Classification (Multi class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7dc276fd-4a1d-448b-a2ca-759feba998f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0101 -6.0302  7.0402]\n",
      " [-0.2487 -1.7462  1.995 ]\n",
      " [ 0.4472  3.3417 -3.7889]\n",
      " [ 0.0302  1.0905 -1.1206]]\n",
      "Predicted y\n",
      "[ -1.0327 -10.098   12.1307]\n",
      "OneHotEncoder(sparse_output=False)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Have to include the bias term\n",
    "X = np.array([[1, 1, 3, -2], [1, -4, 0, -1], [1, 3, 1, 8], [1, 2, 1, 6],[1, 8, 4, 6] ]) \n",
    "#X = np.array()\n",
    "y_class = np.array([[1], [1], [2], [3], [3]])\n",
    "y = np.array([[1, 0, 0],[1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1]])\n",
    "# print(\"One-hot encoding manual\")\n",
    "# print(y_class)\n",
    "# print(y_onehot)\n",
    "w = inv(X.T @ X) @ X.T @ y\n",
    "#w = X.T @ inv(X@ X.T) @ y\n",
    "print(w)\n",
    "\n",
    "Xt = np.array([1,1,-2,4])\n",
    "y_predict = Xt @ w\n",
    "print(\"Predicted y\")\n",
    "print(y_predict)\n",
    "onehot_encoder=OneHotEncoder(sparse_output=False)\n",
    "print(onehot_encoder)\n",
    "Ytr_onehot = onehot_encoder.fit_transform(y_class)\n",
    "print(Ytr_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3e189-7964-4ca6-950e-da8650f96a6f",
   "metadata": {},
   "source": [
    "### Polynomial Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e92f056-502e-4be3-bebc-e8bc24f23673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7634 -1.1183 -1.0423  1.0761  0.7465  1.1014]\n",
      "[[-1], [-1], [-1], [1], [1], [1]]\n",
      "[[1.000e+00 6.000e+00 3.600e+01 2.160e+02 1.296e+03]]\n",
      "[-2.1198]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import matrix_rank\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = np.array([[4], [7], [10], [2], [3], [9]]) \n",
    "y = np.array([-1, -1, -1, 1, 1, 1])\n",
    "## Generate polynomial features\n",
    "order = 4\n",
    "poly = PolynomialFeatures(order)\n",
    "P = poly.fit_transform(X)\n",
    "\n",
    "#w_primal = inv(P.T @ P) @ P.T @ y\n",
    "#w_dual = P.T @ inv(P @ P.T) @ y\n",
    "#print(w_dual)\n",
    "yout = P@w_primal\n",
    "print(yout)\n",
    "yp_class_predict = [[1 if x >=0 else -1 ] for x in yout ] \n",
    "print(yp_class_predict)\n",
    "Pnew =poly.fit_transform([[6]]) \n",
    "print(Pnew) \n",
    "Ynew_poly = Pnew@w_primal\n",
    "print(Ynew_poly) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82417495-0305-4401-818c-bc58f254c13a",
   "metadata": {},
   "source": [
    "### Polynomial (Number of parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "913eaf91-d8ae-4eb9-aac0-7704511fa42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[[ 1.  1.  3.  4.  1.  3.  4.  9. 12. 16.  1.  3.  4.  9. 12. 16. 27. 36.\n",
      "  48. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = np.array([[1, 3, 4], [6, -1, 6], [5, 3, 3], [2, 1, 2]]) \n",
    "order = 3\n",
    "poly = PolynomialFeatures(order)\n",
    "P = poly.fit_transform(X[0].reshape(1, -1))\n",
    "print(len(P[0]))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17529427-c8bc-45e4-9ec7-32bae3e8a789",
   "metadata": {},
   "source": [
    "### Polynomial Classification (Multi Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319dca96-6d14-444a-94b2-30317de876e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.44948975e-03 -9.43531203e-02  6.34920635e-01]\n",
      " [-3.88897256e-03  1.19190567e-01 -5.97883598e-01]\n",
      " [-7.41760392e-03  2.26945495e-01 -1.58730159e-01]\n",
      " [ 1.15336370e-03  7.73185748e-03  9.65608466e-02]\n",
      " [ 1.33775274e-03 -6.14798507e-03  2.38095238e-02]\n",
      " [ 1.05247425e-04 -4.78034174e-04  1.32275132e-03]]\n",
      "[[ 0.00376319 -0.10401106  0.6930275 ]\n",
      " [ 0.00081622 -0.01003306  0.37717333]]\n",
      "[[0, 0, 1], [0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import matrix_rank\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "## Polynomial regression for  \n",
    "## Generate polynomial features \n",
    "X = np.array([[-10], [-8], [-3], [-1], [2]])\n",
    "Y = np.array([[1,0,0], [1,0,0], [0,1,0], [0,0,1], [0,1,0]]) \n",
    "order = 5 \n",
    "poly = PolynomialFeatures(order) \n",
    "## only the data column (2nd) is needed for generation of polynomial terms \n",
    "P = poly.fit_transform(X) \n",
    "Xt = np.array([[-0.1], [0.4]])\n",
    "Pt = poly.fit_transform(Xt) \n",
    "## dual solution (without ridge) \n",
    "Wp_dual = P.T @ inv(P @ P.T) @ Y \n",
    "print(Wp_dual) \n",
    "yp_predict = Pt @ Wp_dual \n",
    "print(yp_predict) \n",
    "yp_class_predict = [[1 if y == max(x) else 0 for y in x] for x in yp_predict ]     \n",
    "print(yp_class_predict) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d738f8b-a928-4d26-84d4-f3ce66a344b4",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a4fc6b3-8f40-4c55-95c7-b840980e1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolynomialFeatures(degree=3)\n",
      "matrix P\n",
      "[[ 1.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.  0.\n",
      "   0.  1.]\n",
      " [ 1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1.  1.\n",
      "  -1.  1.]]\n",
      "[ 0.   0.  -0.1  0.   0.  -0.1  0.   0.1 -0.1  0.   0.  -0.1  0.   0.1\n",
      " -0.1  0.  -0.1  0.1 -0.1  0. ]\n",
      "[ 9.99966915e-07  9.99967142e-07 -9.99980001e-02  9.99970894e-07\n",
      "  9.99969188e-07 -9.99980000e-02  9.99968734e-07  9.99980000e-02\n",
      " -9.99980001e-02  9.99973167e-07  9.99969302e-07 -9.99980000e-02\n",
      "  9.99968165e-07  9.99980001e-02 -9.99980000e-02  9.99969075e-07\n",
      " -9.99980001e-02  9.99980000e-02 -9.99980000e-02  9.99967597e-07]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import matrix_rank\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# X = np.array([-10, -8, -3, -1, 2, 8]).reshape(-1, 1)\n",
    "y = np.array([5, 5, 4, 3, 2, 2]).reshape(-1, 1)\n",
    "X = np.array([[1,0,1], [1,-1,1]])\n",
    "y = np.array([0,1])\n",
    "## Generate polynomial features\n",
    "order = 3\n",
    "poly = PolynomialFeatures(order)\n",
    "print(poly)\n",
    "P = poly.fit_transform(X)\n",
    "print(\"matrix P\")\n",
    "print(P)\n",
    "w_dual = P.T @ inv(P @ P.T) @ y\n",
    "#w_primal = inv(P.T @ P) @ P.T @ y\n",
    "print(w_dual)\n",
    "\n",
    "# X_test = np.array([9]).reshape(-1,1)\n",
    "# P_test = poly.fit_transform(X_test)\n",
    "# pred_poly = P_test @ w_primal\n",
    "# print(pred_poly)\n",
    "\n",
    "# reg_L2 = 0.0001*np.identity(P.shape[0]) #number of rows of P = Dual I\n",
    "# print(reg_L2)\n",
    "# w_dual_ridge = P.T @ (inv(P @ P.T + reg_L2)) @ y\n",
    "# print(w_dual_ridge)\n",
    "\n",
    "# print(\"Approximation with primal ridge regression\")\n",
    "# print(P.shape)\n",
    "reg_L = 0.0001*np.identity(P.shape[1]) #number of columns of P = Primal I\n",
    "w_primal_ridge = inv(P.T @ P + reg_L) @ P.T @ y\n",
    "print(w_primal_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c2bc63-da8a-4e21-a58f-0c891e3297da",
   "metadata": {},
   "source": [
    "### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5173e803-ff0d-4ef2-802c-dbfb659ad009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35431366022592226\n",
      "0.7542315997194405\n",
      "-0.1358858969252995\n",
      "0.0871718814416474\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# Features\n",
    "feature_1 = np.array([-0.709, 1.7255, 0.9539, -0.7581, -1.035, -1.049])\n",
    "feature_2 = np.array([2.8719, 1.5014, 1.8365, -0.5467, 1.8274, 0.3501])\n",
    "feature_3 = np.array([-1.8349, 0.4055, 1.0118, 0.5171, 0.7279, 1.2654])\n",
    "feature_4 = np.array([2.6354, 2.7448, 1.4616, 0.7258, -1.6893, -1.7512])\n",
    "\n",
    "# Target\n",
    "target_y = np.array([0.8206, 1.0639, 0.6895, -0.0252, 0.995, 0.6608])\n",
    "\n",
    "def calc_pearson_correlation(a, b):\n",
    "    cov_ab = np.sum((a - a.mean()) * (b - b.mean())) / len(a)\n",
    "    return cov_ab / (a.std() * b.std() + 1e-8)\n",
    "\n",
    "print(calc_pearson_correlation(feature_1, target_y))\n",
    "print(calc_pearson_correlation(feature_2, target_y))\n",
    "print(calc_pearson_correlation(feature_3, target_y))\n",
    "print(calc_pearson_correlation(feature_4, target_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae77c42-e79f-45e2-be64-33c03104a120",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1553334f-e9da-40cf-b3bb-6bbb05516a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.662110237748184\n",
      "20.085536923187668\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "print(3*math.sin(math.exp(3))*math.sin(math.exp(3))*math.exp(3)*math.cos(math.exp(3)))\n",
    "print(math.exp(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e68e0955-1fb9-4c70-94b1-138e6673660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2337889762251815\n",
      "1.3158756779729237\n",
      "1.6011472035819008\n"
     ]
    }
   ],
   "source": [
    "x = 3\n",
    "for i in range(0,3):\n",
    " x= x-0.1*3*math.sin(math.exp(x))*math.sin(math.exp(x))*math.exp(x)*math.cos(math.exp(x))\n",
    " print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ce08b6a-4352-4442-a232-82ac55178e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x = 3\n",
    "y = 2\n",
    "# Do one at a time cus X affects Y\n",
    "# have to separate gradient with regards to x and y\n",
    "for i in range(0,1):\n",
    " x= x-0.2*(2*x + y*y)\n",
    " #y= y -0.2*(2*x*y)\n",
    " print(x)\n",
    " print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f994a22-d9d0-4373-8f37-a7c83c3a725c",
   "metadata": {},
   "source": [
    "### Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9941f48-1f9e-4542-b5a9-2a6ca72fa4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE list\n",
      "[15.9002  8.9759  7.6895  5.5648  6.874   7.6138  7.6581 10.966  14.7656]\n",
      "Minimum MSE = 5.56475 at threshold index 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def our_own_tree(y):\n",
    "\n",
    "    # split data at first level\n",
    "    # L stands for left, R stands for right\n",
    "    yL, yR = find_best_split(y)\n",
    "\n",
    "    # compute prediction\n",
    "    yL_pred = np.mean(yL)*np.ones(len(yL))\n",
    "    yR_pred = np.mean(yR)*np.ones(len(yR))\n",
    "\n",
    "    y_pred = np.concatenate([yL_pred, yR_pred])\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "#Go through all possible thresholds to determine the best split based on MSE\n",
    "def find_best_split(y):\n",
    "\n",
    "    # index represents last element in the below threshold node\n",
    "    sq_err_vec = np.zeros(len(y)-1)\n",
    "    meansq_err_vec = np.zeros(len(y)-1)\n",
    "    for index in range(0, len(y)-1):\n",
    "\n",
    "        # split the data\n",
    "        data_below_threshold = y[:index+1]\n",
    "        data_above_threshold = y[index+1:]\n",
    "\n",
    "        # Compute estimate\n",
    "        mean_below_threshold = np.mean(data_below_threshold)\n",
    "        mean_above_threshold = np.mean(data_above_threshold)\n",
    "\n",
    "        # Compute total square error\n",
    "        # Note that MSE = total square error divided by number of data points\n",
    "        below_sq_err = np.sum(np.square(data_below_threshold - mean_below_threshold))\n",
    "        above_sq_err = np.sum(np.square(data_above_threshold - mean_above_threshold))\n",
    "        sq_err_vec[index] = below_sq_err + above_sq_err\n",
    "        meansq_err_vec[index] = sq_err_vec[index]/len(y)\n",
    "\n",
    "    #print out MSE\n",
    "    print('MSE list')\n",
    "    print(meansq_err_vec)\n",
    "    best_index = np.argmin(meansq_err_vec)\n",
    "    yL = y[:best_index+1]\n",
    "    yR = y[best_index+1:]\n",
    "    print('Minimum MSE = '+str(meansq_err_vec[best_index])+' at threshold index '+str(best_index+1))\n",
    "    return yL, yR\n",
    "\n",
    "\n",
    "#main\n",
    "S = np.array([0.2, 0.7, 1.8, 2.2, 3.7, 4.1, 4.5, 5.1, 6.3, 7.4])\n",
    "P = np.array([2.1, 1.5, 5.8, 6.1, 9.1, 9.5, 9.8, 12.7, 13.8, 15.9])\n",
    "\n",
    "#sort\n",
    "sort_index = S.argsort()\n",
    "S = S[sort_index]\n",
    "P = P[sort_index]\n",
    "\n",
    "# scikit decision tree regressor\n",
    "scikit_tree = DecisionTreeRegressor(criterion='squared_error', max_depth=1)\n",
    "# Focus on House Size\n",
    "scikit_tree.fit(S.reshape(-1,1), P) # reshape necessary because tree expects 2D array\n",
    "scikit_tree_predict = scikit_tree.predict(S.reshape(-1,1))\n",
    "\n",
    "# Our own tree regressor\n",
    "tree_predict = our_own_tree(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3dd742-4deb-4609-b6e0-a8ba2a5a92d2",
   "metadata": {},
   "source": [
    "### MSE of Regression trees (Check both Up and Down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d666a748-cc1b-4ea2-a887-134322d44cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = [5,13,15,25,6,16,2,19]\n",
    "tot = 0\n",
    "for i in y:\n",
    "    tot += i\n",
    "\n",
    "yb = 13.5\n",
    "\n",
    "tot1 = 0\n",
    "for i in y:\n",
    "    tot1 += (i - yb)*(i - yb)\n",
    "\n",
    "print(tot1/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a198e9d-ac31-43dd-a96b-f2277828c9de",
   "metadata": {},
   "source": [
    "### Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06797cac-947f-4ab7-8076-1b365e902385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "def classification_tree():\n",
    "    \n",
    "    # load data\n",
    "    # iris_dataset = load_iris()\n",
    "    \n",
    "    # # split dataset\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], \n",
    "    #                                                     iris_dataset['target'], \n",
    "    #                                                     test_size=0.20, \n",
    "    #                                                     random_state=0\n",
    "\n",
    "    X_train = [[-2.1, -0.5,0,0.2,1.3,3.8,4.3,4.6,5.8,6.5,7.8,8.2]]\n",
    "    y_train =[[1,0,0,0,1,1,0,0,1,1,1,1]]\n",
    "    \n",
    "    # fit tree\n",
    "    dtree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "    dtree = dtree.fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_trainpred = dtree.predict(X_train)\n",
    "    #y_testpred = dtree.predict(X_test)\n",
    "    \n",
    "    # print accuracies\n",
    "    print(\"Training accuracy: \", metrics.accuracy_score(y_train, y_trainpred))\n",
    "    #print(\"Test accuracy: \", metrics.accuracy_score(y_test, y_testpred))    \n",
    "\n",
    "    # Plot tree\n",
    "    tree.plot_tree(dtree)\n",
    "\n",
    "classification_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212bdd3-40c6-4a53-826d-c48436a6178a",
   "metadata": {},
   "source": [
    "### Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1b60f16-5495-4414-91b6-f0820c8276f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[ 5  0  5]\n",
      " [10 17 10]\n",
      " [20  0 20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import matrix_rank\n",
    "X = np.array([[5, 0, 5], [10, 17, 10], [20, 0, 20]])\n",
    "#X = np.array([[1, 0], [1, 1]])\n",
    "print(matrix_rank(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370c28a-6051-436e-848b-119570b0fdfd",
   "metadata": {},
   "source": [
    "### Multiple orders polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc32caaa-7418-49a8-889e-c0556300f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyreg\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "# training data\n",
    "x = np.array([-10, -8, -3, -1, 2, 7]).reshape(-1, 1)\n",
    "y = np.array([4.18, 2.42, 0.22, 0.12, 0.25, 3.09]).reshape(-1, 1)\n",
    "\n",
    "# test data\n",
    "xt = np.array([-9, -7, -5, -4, -2, 1, 4, 5, 6, 9]).reshape(-1, 1)\n",
    "yt = np.array([3, 1.81, 0.80, 0.25, -0.19, 0.4, 1.24, 1.68, 2.32, 5.05]).reshape(-1, 1)\n",
    "all_mse = []\n",
    "all_w = []\n",
    "for i in range(1, 6):\n",
    "    w = polyreg.fit_primal(x, y, d=i, lmbda=-1)\n",
    "    \n",
    "    y_train_pred = polyreg.predict(x, w, d=i)\n",
    "    train_mse = np.mean((y_train_pred - y) * (y_train_pred - y))\n",
    "\n",
    "    y_test_pred = polyreg.predict(xt, w, d=i)\n",
    "    test_mse = np.mean((y_test_pred - yt) * (y_test_pred - yt))\n",
    "\n",
    "    all_w.append(w)\n",
    "    all_mse.append((train_mse, test_mse))\n",
    "\n",
    "w = polyreg.fit_dual(x, y, d=6, lmbda=-1)\n",
    "    \n",
    "y_train_pred = polyreg.predict(x, w, d=6)\n",
    "train_mse = np.mean((y_train_pred - y) * (y_train_pred - y))\n",
    "\n",
    "y_test_pred = polyreg.predict(xt, w, d=6)\n",
    "test_mse = np.mean((y_test_pred - yt) * (y_test_pred - yt))\n",
    "\n",
    "all_w.append(w)\n",
    "all_mse.append((train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f8d27-34fd-4d1b-8d33-bfae3acde0a0",
   "metadata": {},
   "source": [
    "### Order = 1, 2, 3, 4, 5, 6, with regularization (lambda = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c9580f3-bf6b-4b78-992d-d52fc71059e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mse = []\n",
    "all_w = []\n",
    "for i in range(1, 7):\n",
    "    w = polyreg.fit_primal(x, y, d=i, lmbda=1)\n",
    "    \n",
    "    y_train_pred = polyreg.predict(x, w, d=i)\n",
    "    train_mse = np.mean((y_train_pred - y) * (y_train_pred - y))\n",
    "\n",
    "    y_test_pred = polyreg.predict(xt, w, d=i)\n",
    "    test_mse = np.mean((y_test_pred - yt) * (y_test_pred - yt))\n",
    "\n",
    "    all_w.append(w)\n",
    "    all_mse.append((train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a28309-3e1b-4c01-81b4-becee7b4e54b",
   "metadata": {},
   "source": [
    "### K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aeaa276c-2b9a-4a81-b1ba-3c2e21a39efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 1 1 2 2]\n",
      "Converged centers: [[ 0.  10.5]\n",
      " [ 0.  16.8]\n",
      " [ 0.  21. ]]\n"
     ]
    }
   ],
   "source": [
    "# Data points\n",
    "import numpy as np\n",
    "x1 = np.array([0, 10])\n",
    "x2 = np.array([0, 11]) \n",
    "x3 = np.array([0, 16])\n",
    "x4 = np.array([0, 16]) \n",
    "x5 = np.array([0, 16])\n",
    "x6 = np.array([0, 18]) \n",
    "x7 = np.array([0, 18])\n",
    "x8 = np.array([0, 21])\n",
    "x9 = np.array([0, 21])\n",
    "x10 = np.array([0, 99])\n",
    "data_points = np.array([x1, x2, x3, x4, x5, x6, x7, x8, x9])\n",
    "\n",
    "c1_init = x1\n",
    "c2_init = x4\n",
    "c3_init = x8\n",
    "centers = np.array([c1_init, c2_init, c3_init])\n",
    "\n",
    "def k_means(data_points, centers, n_clusters, max_iterations=100, tol=1e-10):\n",
    "    for _ in range(max_iterations):\n",
    "        \n",
    "        # Assign each data point to the closest centroid\n",
    "        labels = np.argmin(\n",
    "            np.linalg.norm(data_points[:, np.newaxis ] - centers , axis =2) \n",
    "            , axis =1)\n",
    "        \n",
    "        # Update centroids to be the mean of the data points assigned to them\n",
    "        new_centers = np.zeros((n_clusters , data_points.shape[1]))\n",
    "        \n",
    "        # End if centroids no longer change\n",
    "        for i in range(n_clusters):\n",
    "            new_centers[i] = data_points[labels == i].mean(axis=0)\n",
    "        \n",
    "        if np.linalg.norm(new_centers - centers) < tol: \n",
    "            break\n",
    "            \n",
    "        centers = new_centers\n",
    "    \n",
    "    return centers , labels\n",
    "\n",
    "\n",
    "centers, labels = k_means(data_points, centers, n_clusters=3, max_iterations = 100) \n",
    "print(labels)\n",
    "print(\"Converged centers:\", centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb087590-8a34-45b7-b116-7770b0103c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954434002924965\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "a = - (5/8)*math.log2(5/8) - (3/8)*math.log2(3/8) \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5c340877-d4c1-428a-a147-c40982401298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63628933528331"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*(2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6225cc61-fb9e-48ec-aa25-0fa58c00f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46875\n"
     ]
    }
   ],
   "source": [
    "n = 1 - (5/8)*(5/8) - (3/8)*(3/8)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7d42645f-0202-4877-8ad6-1fdb76865678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n*(2/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28dff18-58db-45fd-9de7-482168da733e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
